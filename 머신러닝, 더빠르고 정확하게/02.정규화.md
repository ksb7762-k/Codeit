머신 러닝 모델이 정확한 예측을 못하는 경우가 많음  
이번 챕터에서는 이런 문제를 해결하는 방법을 배움  

## 편향과 분산   

모델이 너무 간단해서 데이터의 관계를 학습하지 못하는 경우, 편향(bias)이 높다고 말함    

예시 

![](/image.png/05.8.PNG)  

이번에는 모델의 복잡도를 늘려서 (높은 차항의 회귀를 이용해서) 모델을 학습시켰다고 하자  

예시  

![](/image.png/05.9.PNG)    

그렇다면 편향이 낮은 모델이 높은 모델보다 항상 더 좋을까? ==>  그건 아님  

데이터셋 별로 모델이 얼마나 일관된 성능을 보여주는 지를 분산이라고 함  

성능 차이가 많이 나면 분산이 높다, 성능 차이가 없으면 분산이 낮다고 함 


## 편향-분산 트레이드오프(Bias-Variance Tradeoff)   

![](/image.png/05.10.PNG)       

![](/image.png/05.11.PNG)      

일반적으로 편향과 분산은 하나가 줄어들수록 하나는 늘어나는 관계가 있음 ==> 이걸 편향-분산 트레이드오프라 부름   
적당한 밸런스를 찾아내는 게 중요! 

즉 아래와 같은 곡선을 찾아야함  

![](/image.png/05.12.PNG)    

## 정규화(Regularization) 개념  

모델이 과적합 돼서 다음과 같은 복잡한 다항함수가 나왔다고 하자   

![](/image.png/05.13.PNG)     

함수가 급격하게 변하는 이유는 세타값들이 크기 때문임   

![](/image.png/05.14.PNG)    


정규화는 모델을 학습시킬 때 세타값들이 너무 커지는 걸 방지해서 과적합을 예방   

트레이닝 데이터에 대한 오차값은 커질 수 있어도 가설함수를 완만하게 만들어서 여러 데이터 셋에서 일관된 성능을 보임    

![](/image.png/05.15.PNG)  
  

