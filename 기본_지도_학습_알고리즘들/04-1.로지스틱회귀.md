## 분류 문제  

이번 챕터에서는 분류 문제를 다룸    
예를 들어 어떤 이메일이 스팸인지 아닌지,  어떤 기사가 정치 기사인지 스포츠   기사인지 연예 기사인지 등  
보통 분류 문제를 풀 때는 각 결과값에 숫자값을 지정해줌    

![](/image.png/04.1.PNG)

선형 회귀로도 분류 가능 

![](/image.png/04.2.PNG)  

하지만 다음과 같이 이상치가 존재한다면? 

![](/image.png/04.3.PNG)

선형회귀는 이상치에 민감하게 반응하기 떄문에 분류에 잘 사용하지 않음  

그렇다면 분류를 하고 싶을 때는 무엇을 해야할까?  ==> 로지스틱 회귀 사용   

## 로지스틱 회귀 (Logistic Regressoin)  

: 데이터에 가장 잘 맞는 시그모이드 함수를 찾음  

그래프로 나타내면 다음과 같이 생김 

![](/image.png/04.4.PNG)  

시그모이드 함수는 무조건 0과 1사이의 결과를 리턴하기 때문에 분류를 할 때 더 유용함   
  이상치에 영향을 거의 받지 않음   

그런데 로지스틱 회귀는 회귀가 아니라 분류를 하기위해 쓰인다는데 왜 이름이 로지스틱 회귀일까?    
==> 따지고 보면 시그모이드 함수의 결과값도 0과 1사이의 연속적인 값이기 때문에 회귀라고 볼 수 있음   

![](/image.png/04.5.PNG) 

우리는 주로 시그모이드 함수의 결과값이 0.5보다 큰지 작은지로 분류   
그래서 이름은 로지스틱 회귀지만 분류할 때 사용  

## 로지스틱 회귀의 가설 함수  



선형회귀에서 썼던 가설함수를 발전시키면 로지스틱 회귀의 가설함수가 나옴    

로지스틱 회귀의 가설함수를 h로 놓기 위해 선형 회귀 가설함수를 g로 표현  

로지스틱 회귀 가설 함수는 다음과 같이 표현     

 
![](/image.png/04.6.PNG)   

함수 g는 일차함수 따라서 결과값이 엄청 클수도 엄청 작을 수도 있음  
   하지만 시그모이드 함수에 어떤 인풋을 넣든 간에 0과 1사이로 값이 떨어짐  

그렇다면 0과 1사이의 수로 무엇을 하는 걸까?  

## 로지스틱 가설 함수의 의미  

가설함수가 하는 일이 공부시간을 바탕으로 시험을 통과할지 예측하는 것이라고 가정  

0은 탈락, 1은 통과를 의미 그리고 x는 다음과 같은 벡터라고 하자   

![](/image.png/04.7.PNG)  

x0은 항상 1이니까 무시하고 x1이 50이라는 건 학생이 50시간 공부했다는 걸 의미   
x를 가설함수에 넣었더니 가설함수 값이 0.9가 나왔다고 하자.  이것이 무슨 의미일까?  

==> 목표변수가 1일 확률이 90퍼센트라는 것을 의미   
  
![](/image.png/04.8.PNG)    

확률이 50퍼센트가 넘으니까 분류를 하자면 이 학생은 통과한 학생으로 분류하면 됨    

## 결정 경게 (모든 분류 문제에 적용 가능)  

그렇기 때문에 가설함수의 아웃풋이 0.5인 공부시간을 알아내면  

![](/image.png/04.9.PNG)   


다음과 같이 예측할 수 있음   

![](/image.png/04.10.PNG)   

이렇게 분류를 할 때 구별하는 경계선을 Decision Boundary라고 함  

속성이 2개일 때 로지스틱 회귀 가설 함수를 시각화 하는것은 어려움   
하지만  Decision Boundary를 시각화 하는 것은 쉬움    

공부 시간x1, 모의고사 점수x2라고 했을 때 다음과 같은 가설 함수를 만들 수 있음  

![](/image.png/04.11.PNG)     


이 함수의 결과가 0.5이상이면 시험을 통과, 미만이면 탈락을 예측   

위의 가설함수를 풀면 x1과 x2의 관계식을 구할 수 있고 이 함수가 데이터를 분류하는 기준선이 됨   

![](/image.png/04.13.PNG)  

## 로그 손실  (log-loss / cross entropy)  
: 손실의 정도를 로그 함수로 결정함  

로지스틱 회귀 가설함수의 성능을 평가하는 손실 함수 필요    
이때 MSE를 사용하지 않고 로그 손실을 사용함!     

![](/image.png/04.14.PNG) 

로그손실 함수는 예측값이 실제값과 얼마나 괴리가 있는지 알려줌    
그런데 로지스틱 회귀는 분류 알고리즘이고 분류가 2가지라고 가정하면 가능한 목표변수가 1과 0 뿐임    

가설함수 값이 0.8이라면 80퍼센트의 확률로 y는 1이다!  

![](/image.png/04.15.PNG) 

h0(x)가 1에서 멀어질수록 잘 못하고 있는 거니까 손실을 엄청나게 키움    

가설함수 값이 0.2라면 20퍼센트의 확률로 y는 1이다!    

![](/image.png/04.16.PNG)  

h0(x)가 0에서 멀이질수록 잘 못하고 있는 거니까 손실을 엄청나게 키움       

## 로지스틱 회귀 손실 함수  

![](/image.png/04.17.PNG) 

위의 식에 y=0과 y=1을 대입    

![](/image.png/04.18.PNG)   

즉, 모든 데이터의 로그 손실을 계산한 후, 평균을 내서 가설함수를 평가    
  
복습)  가설함수는 세타값들을 어떻게 설정하느냐에 따라 바뀜  

위의 식에 로그손실 함수를 대입하면 ?  

![](/image.png/04.19.PNG) 

~~로지스틱 경사 하강법~~ 

## 분류가 3개 이상일 때   

예시)  
 메일을 직장, 친구, 스팸으로 분류한다고 가정 

각 옵션에 숫자를 붙이자          
![](/image.png/04.20.PNG)  

그래프로 나타내면?    


![](/image.png/04.21.PNG)   

우선 어떤 메일이 직장메일인지 아닌지로 분류    

![](/image.png/04.22.PNG)   


친구, 스팸도 같은 방법으로 분류  

그리고 이메일 데이터의 입력변수들을 세 개의 가설함수에 각각 넣고 가설함수의 값이 가장 큰 것으로 예측!      

예시)   
![](/image.png/04.24.PNG)

~~로지스틱 회귀 정규방정식~~  



