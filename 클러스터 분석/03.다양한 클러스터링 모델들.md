거리 말고 어떤 게 클러스터링의 기준으로 사용될 수 있는지부터 간단히 알아보자  

## 계층 기반 클러스터링  

계층 구조를 바탕으로 클러스터링을 진행함  
기본적으로 유사한 데이터를 묶은 클러스터들을 층으로 쌓아가며 클러스터링하는 방식  
 

 ![](/image.png/08.21.PNG)   

 시각화된 결과물을 통해 테이터 간 관계를 쉽게 파악할 수 있고, 원하는 수의 클러스터로 간단히 구분 가능  

 ## 밀도 기반 클러스터링  

 밀도가 높은 부분을 같은 클러스터로 묶어 나가는 방법   
 어떤 데이터가 클러스터에 속할 경우 클러스터 내에 다른 많은 데이터가 가까운 위치에 있을 것이라는 생각에서 출발  
 밀도 기반 클러스터링은 기하학적인 형태의 데이터를 클러스터링할 때 효과적  


![](/image.png/08.22.PNG)  


 ## 분포 기반 클러스터링   

 각 클러스터에 포함된 데이터들이 정규분포를 따른다고 가정했을 때, 특정 데이터가 포함될 확률이 가장 높은 분포의 클러스터가 무엇인지를 찾아 클러스터를 나누는 방법  

  
![](/image.png/08.23.PNG)   

## 계층적 클러스터링(Hierachical Clustering)이란? 

순차적으로 유사한 데이터끼리 같은 클러스터로 묶어 나가는 모델  
데이터를 아래에서부터 묶어 나간다고 해서 Bottom-up 클러스터링이라고도 함  

### 과정  

먼저 각 데이터 사이의 거리를 모두 계산하여 가장 가까운 데이터 쌍을 차례대로 묶어나감  

![](/image.png/08.24.PNG) 

묶인 데이터 쌍 끼리도 거리를 계산하여 가까운 쌍은 하나로 묶음  

![](/image.png/08.25.PNG) 

모든 데이터가 하나의 클러스터로 묶일 때까지 이 과정을 반복함

![](/image.png/08.26.PNG) 


모든 클러스터의 계층이 구분되어 연결된 이 상태의 그래프를 덴드로그램Dendrogram)이라고 함  


계층적 클러스터링은 이 덴드로그램을 이용해 원하는 개수로 클러스터를 나눌 수 있음!  

만약 클러스터의 개수를 3개로 하고 싶다면 아래와 같이 구분  

계층에 따라 A,B,C,D/E/F,G,H,I가 각각 하나의 클러스터로 묶임  

![](/image.png/08.27.PNG) 

클러스터를 4개로 나누고 싶다면 다음과 같이 해주면 됨.   

3개일 때는 F,G,H,I가 하나의 클러스터였는데 이번엔 I가 다른 클러스터로 분류됨  

![](/image.png/08.28.PNG) 

그렇다면 계층을 묶을 때 특정 데이터가 서로 유사하다는 것은 어떻게 정의할 수 있을까?  

다양한 방법이 있는데 대표적으로 **Ward 거리**라는 개념을 사용  

## Ward 거리  

Ward 거리란 각 클러스터의 Center와 속한 데이터들 사이 거리를 제곱하여 더한 값의 증가분을 의미  

예를 들어, 위의 이미지에서 클러스터롤 4개로 나눴을 때는 F,G,H와 I가 서로 다른 클러스터로 분류됐음   

이 상태에서 F,G,H 세 데이터의 중심점과 각 테이터 사이 거리의 제곱합이 있을텐데, I까지 하나의 클러스터로 묶이게 되면 이 값이 조금 더 커질 것임  
이 두 값 사이의 차이(증가분)가 Ward 거리임  

계층적 클러스터링은 이 값이 최대한 작게 증가되는 순서로 계층을 묶어 나감  

 ## 계층적 클러스터링의 장단점  

 장점 : 모델을 학습시킬 때 클러스터의 개수를 미리 가정하지 않아도 됨  
k-means는 사전에 정한 k 값에 따라 결과가 달라졌지만, 계층적 클러스터링은 클러스터의 개수에 상관없이 모델 학습이 가능  

단점: 모든 데이터끼리의 거리를 반복해서 계산해야 하기 때문에 많은 연산이 필요  
때문에 학습 속도가 느리고 대용량 데이터에 적용이 어려움  


## DBSCAN이란?  

DBSCAN이란 Density-Based Spatial Clustering of Applications with Noise의 줄임말  
영어 표현 그대로 밀도 기반 클러스터링 방법  


전제는 다음과 같음  
- 어떤 데이터가 특정 클러스터에 속할 경우, 클러스터 내의 다른 데이터들과 가까운 위치에 있어야 한다   


DBSCAN은 **다른 많은 데이터와 가까운 위치** 이 두 가지를 통해 클러스터를 구분함  
  
  그렇다면 얼마나 많은 데이터와 얼마나 가까운 위치에 있어야 하나의 클러스터로 분류할까?  

  이 두가지는 모델 학습 시 임의로 지정해 줘야함  

  얼마나 가까운 위치에 데이터가 있어야 하는지 ==> **반경(Radius)**  
  반경 내에 얼마나 많은 데이터가 있어야 하는지 ==> **최소 데이터 개수(Minimum Points)**   

### 과정  

먼저, 특정 데이터에서 지정한 반경 내애 몇 개의 데이터가 포함되는지 탐색  


![](/image.png/08.29.PNG)   

정해진 반경 내에 최소 데이터 개수가 포함되면 하나의 클러스터로 묶음.  
 만약에, 최소 데이터 개수가 4개라고 하면 아래 이미지에는 두 개의 클러스터가 생기게 됨. 


![](/image.png/08.30.PNG)  

만들어진 두 개의 클러스터의 경계에 있는 데이터들에서 그린 반경이 서로 겹치는 경우가 생길 수 있음.  

그럴 경우에는 두 클러스터를 하나로 묶음  

![](/image.png/08.31.PNG)   

조건에 만족하지 못하고 어떠한 클러스터에도 포함되지 못한 데이터는 이상치(Outlier)가 됨  

![](/image.png/08.32.PNG)    

k-means는 이상치가 Centroid 위치에 관여하면서 결과에 영향을 끼쳤음  
 DBSCAN은 기준에 포함되지 못하는 데이터를 제외하기 때문에 이상치에 강건(Robust)한 방법임  

또, 데이터의 밀도에 따라 클러스터를 만들기 때문에 복잡하나 기하학적인 형태를 가진 데이터셋 효과적임  

반면, 고차원 데이터일수록 데이터 간 밀도를 계산하기 어렵고 연산이 많아져 학습속도가 느려질 수 있다는 단점이 있음 

## GMM이란?  

GMM(Gausian Mixture Model)은 데이터가 서로 다른 k 개의 정규뷴포에서 생성되었다고 가정  

데이터가 정규 분포를 따를 때 가장 큰 이점은 값이 특정 구간에 속할 확률을 계산할 수 있다는 것!  


GMM은 이 확률을 통해서 클러스터를 구분함  

예시) 
아래 3개의 정규분포가 있다고 하자  

- F1(X) : 평균 = -2, 표준 편자 = 1  
- F2(X) : 평균 = 1.5, 표쥰 편차 = 1.5  
- F3(X) : 평균 = 5, 표준 편차 = 2  

그림으로 나타내면 아래와 같음  

![](/image.png/08.33.PNG)  

만약 6이라는 데이터가 관측되었을 때, 해당 데이터는 어떤 정규 분포에 속한다고 하는 게 가장 자연스러울까?  


평균에서 멀어질수록 확률이 작아진다는 것을 생각했을 때, 6이라는 데이터가 F1(X), F2(X)에 속할 확률은 매우 작음  

 아마도 평균이 6에 가장 가깝고, 분산도 큰 F3(X)에 속할 확률이 가장 높을 것임  


따라서, 6이라는 데이터는 F3(X)에 속하는 클러스터로 분류할 수 있음  


이런 식으로, 특정 데이터의 값이 어떤 분포에 포함될 확률이 더 큰지를 따져서 각 클러스터로 구분하는 게 GMM의 방법론임  


GMM을 사용하면 데이터가 단순하게 원형으로 분포되어 있을 때 뿐만 아니라, 좀 더 복잡한 형태(타원형, 비대칭 등)의 데이터도 효과적으로 클러스터링을 할 수 있음  
 
![](/image.png/08.34.PNG)   

단점: k-means와 비슷하게 사전에 클러스터 개수를 임의로 설정해야
하고 그 값에 따라서 결과가 달라질 수 있음  

또 특정 분포에 할당되는 데이터 수가 적으면 모수 추정이 잘 이뤄지지 않기 때문에 충분히 많은 수의 데이터가 있지 않으면 적용하기 어려움  

마지막으로 정규 분포를 따른다고 가정하는 데이터를 구분해 주는 방법이기 때문에, 정규 분포가 나올 수 없는 범주형 데이터는 다룰 수 없음  

## 클러스터링과 머신러닝  

클러스터링은 머신 러닝 기법 중 비지도 학습에 해당함   
비지도 학습은 정답(레이블)을 주지 않은 상태에서 데이터의 특성만 가지고 스스로 규칙을 찾아내는 방식  

즉, 클러스터링은 데이터들이 특정 클러스터에 할당될 뿐, 그 클러스터가 무엇을 의미하는지가 함께 결과로 나오진 않음  
 ==> 해당 클러스터가 무엇을 의미하는 지는 분석하는 사람이 별도로 해석해야함  



