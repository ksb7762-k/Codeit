## 경사 하강법 테크닉

- 손실함수의 극소점으로 가는 것이 목표  
- 계속해서 가설함수를 개선해서 아래로 내려감  
- 손실함수의 기울기를 이용 (- 붙여서 사용)  
- 현재 $ \theta_0 = -3 $,  $ \theta_1 = -3 $ 이라고 가정    

![](/image.png/경사하강1.png)


- 기울기 벡터에 -3, -3을 대입하면 현재 기울기는 -6, -12    
- 이 기울기를 이용해서 $\theta_0 $, $ \theta_1 $ 수정  
- $ \theta_0 $은 원소 1, $\theta_1 $은 원소 2를 이용해서 수정  
- $ \theta_0 $에 기울기 벡터 원소 1을 더하면 올라가므로 빼야 함  
- 그냥 빼는 게 아니라 학습률 $ \alpha $를 곱해서 뺌    

![](/image.png/경사하강1.png)

![](/image.png/경사하강2.png)

## 학습률 $ \alpha $

- 경사를 타고 내려갈 때 얼마나 많이 움직일지 나타내는 수치  
- 학습률이 크면 한 번에 많이, 작으면 적게 움직임  
- 학습률을 0.1이라고 가정  

![](/image.png/학습률1.png)

  
- $ \theta_1 $도 마찬가지    

![](/image.png/학습률2.png)  


## 그래프

![](/image.png/학습률%20그래프.png)  


## 경사 하강법 일반화

![](/image.png/경사일반화.png)  


## 학습률 $ \alpha $가 너무 큰 경우

![](/image.png/학습률큰.png)  


## 학습률 $ \alpha $가 너무 작은 경우

![](/image.png/학습률작은.png)  


- 일반적으로 1.0 ~ 0.0 사이 숫자로 설정 (1, 0.1, 0.01, 0.001 또는 0.5, 0.05, 0.005 등)  
- 여러 개를 실험해서 손실이 잘 줄어드는 학습률 선택  

## 모델 평가하기

- 가설함수는 세상에 일어나는 함수를 수학적으로 표현한다는 의미에서 모델이라 부름  
- 데이터를 이용해서 모델을 개선시키는 것을 학습이라 함  
- 모델을 학습시키고 나서는 얼마나 예측을 잘하는지 평가  

### 평균 제곱근 오차 (RMSE)

- MSE에 루트를 씌운 것  
- 예: 집 가격 예측 시 목표변수 단위는 원 → 제곱하면 원² → 루트를 씌워 다시 단위를 원으로 만듦  

- 함정: 학습 데이터에 맞게 학습시켰기 때문에 MSE가 낮을 수밖에 없음  
- ⇒ 학습과 평가 데이터를 나눠야 함  

- 예시: 30개 데이터를 24개 학습, 6개 평가  
- 24개로 모델 학습 후 평가 데이터로 신빙성 있게 모델 평가

![](/image.png/데이터나누기.png)  
