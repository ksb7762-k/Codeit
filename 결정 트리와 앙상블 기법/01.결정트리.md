## 결정 트리 (Decision Tree) 

예/아니오로 답할 수 있는 질문들 + 이 질문들에 답해가면서 분류하는 알고리즘 

예시) 교통 사고가 났을 때 생존 여부를 분류한다고 하자  

![](/image.png/07.1.PNG)

만약 데이터가 주행속도 즉, 특정 숫자값이라면?

시속 100km가 넘었나요?와 같은 질문도 할 수 있음 
![](/image.png/07.2.PNG)

질문들에 답을 해가면서 한 단계씩 내려감  
  보라색 박스에 도착하면 해당 분류값을 리턴   
  한 속성을 한 번만 사용해야 하는 것은 아님  

예시   


![](/image.png/07.3.PNG)  



컴퓨터 과학에서는 한 지점에서 시작해서 점점 넓게 퍼져 나가는 걸 트리라고 함  
박스 하나 하나를 노드라고 함   
   가장 위에있는 질문 노드를 root노드, 트리의 가장 끝에 있는 노드들을 leaf 노드라고 함  
   leaf 노드는 생존, 사망과 같은 특정 에측 값을 가지고 있음    

## 지니 불순도 (Gini impurity) 

결정 트리를 만들 때 각 노드에 어떤 질문이나 분류가 들어갈지 어떻게 고를까?   

머신러닝 프로그램이 결정트리를 만들 때는,   
 위의 예시처럼 질문이 정해져 있는 상태로 만드는게 아니라 경험을 통해 직접 정해나가야 함   

즉, 여러 데이터를 분류하면서 각 위치에서 어떤 노드가 좋을지 고르는 것   
이걸 제대로 하려면 어떻게 분류하거나 질문하는게 좋은지에 대한 기준이 필요함    
 
결정트리에서는 이걸 *지니 불순도*를 통해서 함   
지니 불순도 : 데이터셋 안에 서로 다른 분류들이 얼마나 섞여 있는지 나타냄  

예시)   

![](/image.png/07.4.PNG)  


지니 불순도는 데이터셋이 얼마나 불순한지 숫자로 표현   

![](/image.png/07.5.PNG)  

![](/image.png/07.6.PNG)    

지니 불순도가 낮을수록 순수한 데이터  

## 결정 트리 만들기 

지니불순도를 이용해서 결정트리의 노드를 정해보자  

독감환자 데이터 셋을 예시로 보자     

고열, 기침, 몸살여부(속성)로 독감 여부(목표변수)를 예측 

 ![](/image.png/07.7.PNG) 

처음에는 가장 위에 있는 root node를 만들어야 하는데  선택지가 뭐가 있을까?  

 질문노드를 만들지 않고 바로 분류노드 만든다면 
모든 데이터는 독감이다 일반 감기다 등의 분류노드를 만들 수 있을 것임 


또는  

 고열이 있나요? 기침이 있나요? 몸살이 있나요? 이 세 질문 중 하나를 질문노드로 만들 수 있음 

어떤 걸 골라야 할까? ==> 지니 불순도 활용    


이번에는 지니 불순도를 사용해서 분류노드를 만드는게 얼마나 좋은지 평가하는 법을 배움 

루트노드를 *분류노드*로 만든다고 가정  

학습에 사용하는 데이터 수 : 90개라 가정  
  루트노드는 가장 위에 있는 노드니까 모든 데이터가 거쳐감 그래서 90개를 모두 사용  


![](/image.png/07.8.PNG) 

좋은 분류노드는 최대한 맞게 분류 해야함  

==> 여기 모든 데이터를 하나의 분류로 예측했을 때 가장 많이 맞야야함  
   지금 같은 경우 독감 데이터가 일반 감기 데이터보다 많기 때문에 독감 노드를 고름 

그럼 이 독감 노드는 정확히 얼마나 좋은걸까?  

불순도를 계산하면 다음과 같음  

![](/image.png/07.9.PNG)  

지금은 불순도가 꽤 높음  

데이터가 불순할 때 분류노드를 만들면 성능이 별로임   


이번에는 만들려는 *질문 노드*가 얼마나 좋은지 평가하는 법을 보자   

결정트리에서 좋은 질문은 데이터를 잘 나누는 질문  

여러 분류의 데이터가 섞여있을 때  데이터가 2분류(독감 or 일반감기)로 나뉘는데  
 고열이 있는 데이터는 모두 독감, 고열이 없는 데이터는 모두 일반 감기라면  데이터를 엄청 잘 나눈 것 
 

![](/image.png/07.10.PNG)   

만약 해당 질문에 따라 나눴을 때 데이터에 독감과 일반감기 데이터가 많이 섞여있으면 안좋은 질문  

![](/image.png/07.11.PNG) 

좋은 질문은 데이터를 잘 나눠서 아래 노드들이 분류하기 쉽게 만들어줌  
  
질문으로 나뉜 데이터셋의 지니불순도가 낮을수록 (데이터셋이 순수할수록) 더 좋은 질문  


따라서 질문노드의 성능을 판단할 때는 나뉜 데이터 셋의 지니불순도를 사용  
각각의 지니불순도를 구하고 각 데이터의 개수만큼 무게를 줘서 평균을 냄   

![](/image.png/07.12.PNG) 

## 노드 고르기  

지난 레슨에서는 특정 분류 또는 질문 노드가 얼마나 좋은지를 지니 불순도를 써서 나타냄  
 

 만약 분류노드의 불순도가 가장 작으면 이미 데이터가 잘 나눠져 있기 때문에 그대로 분류해도 된다는 뜻  

질문 노도의 불순도가 가장 작으면 질문을 통해서 지금 있는 데이터셋보다 불순도를 더 낮출 수 있다는 듯   

![](/image.png/07.13.PNG) 

나머지 질문 노드의 불순도도 계산했다고 치자 

![](/image.png/07.14.PNG)   

몸살이 있나요?의 불순도가 가장 낮기 때문에 root노드의 질문노드로 고름!

## 모든 노드 고르기   

루트 노드가 몸살이 있나요?라고 가정하고 
루트 노드의 왼쪽을 살펴보자   

![](/image.png/07.15.PNG)   

여기서 만들 수 있는 노드들은 다음과 같다  


![](/image.png/07.16.PNG) 

몸살이 있는 데이터는 모두 독감이 있다고 분류할 때의 불순도를 계산 

예시)   
 
독감 있는 사람이 더 많으니까 독감 분류 노드로 만들면 됨  

![](/image.png/07.17.PNG)  

다음은 고열이 있나요?로 나눌 때와 기침이 있나요?로 나눌 때의 불순도를 계산  

![](/image.png/07.18.PNG) 

세 가지 선택지 중에서 고열이 있나요?라는 질문 노드를 사용했을 때 지니 불순도가 가장 낮음   
==>  따라서 이 질문을 노드로 만들어 주면 됨    

![](/image.png/07.19.PNG) 

방금 이 과정들을 트리의 맨 끝에 leaf 노드들이 모두 분류노드가 될 때까지 반복해주면 됨  

 반복하면 다음과 같은 결정트리가 만들어짐  

트리가 몇 층까지 내려가는지를 '트리 깊이'라고 표현  

'깊이 3 이상은 내려가지마라' 이렇게 정해줄 수도 있음  

 특정 높이까지 내려오면 더 이상 불순도를 비교하는게 아니라 멈추고 분류노드를 만듬   
  (파이썬에서는 max_depth로 표기하고 optional parameter에 해당)

![](/image.png/07.20.PNG) 

 ## 속성이 숫자형일 때 질문 노드  

 예시로 체온 데이터를 보자 

 ![](/image.png/07.21.PNG) 

먼저 체온 데이터를 정렬시키고 각 연속된 데이터의 평균을 계산함   
그리고 이 평균들을 이용해서 질문들을 하나씩 만듬   

그 다음에 모든 평균 체온 데이터에 대해서 지니불순도를 계산 

![](/image.png/07.22.PNG)  

체온이 37.5를 기준으로 나눴을 때 지니 불순도가 가장 낮다고 가정  

그리고 37.5도가 넘나요? 몸살이 있나요? 기침이 있나요? 이 세 질문과 독감 분류 노드들 중 지니 불순도가 가장 낮은 것을 선택하면 됨    

참고로 다음 노드를 만들 때도 자동으로 똑같이 체온 질문을 “37.5가 넘나요?”로 사용하는 건 아님  

 매번 노드를 만들 때마다 위에서 했던 것처럼 해당 노드까지 오는 학습 데이터에 대해서 가장 좋은 체온 질문을 찾아내야 함 

## 속성 중요도 (Feature importance) 

결정 트리의 장점 중 하나가 쉽게 해석할 수 있다는 것  

즉, 어떤 속성이 중요하게 사용됐는지 알 수 있음   

이번 레슨에서는 속성 중요도를 계산하는 방법을 배움  

속성 중요도를 계산하기 위해서는 각 노드 하나 하나의 중요도인 *노드 중요도(Node importance)* 를 알야아 함 

![](/image.png/07.23.PNG)  

n : 중요도를 계산하려는 노드까지 오는 학습데이터의 수  

GI : 이 노드까지 오는 데이터셋의 불순도  

m : 전체 학습 데이터의 수  


예시  

![](/image.png/07.24.PNG)  

그렇다면 이 중요도는 무엇을 수치화 한걸까?  

위 노드에서 아래 노드로 내려오면서, 불순도가 얼마나 줄어들었는지를 계산!  

즉 그 노드를 전후로 불순도가 얼마나 낮아졌는지를 알 수 있음    

불순도가 낮아질수록 나눠지는 데이터셋들이 점점 독감이나 일반감기 데이터 중 하나가 비중이 커지고 있다는 것을 의미    

'나눠지는 데이터셋들에 대해서 점점 알아간다 또는 더 많은 정보를 얻는다' 라고 해서  
 이 수치를 정보 증가량 (information gain)이라고도 부름 

이렇게 모든 노드의 중요도를 계산하면 특정 속성이 얼마나 중요한지를 계산할 수 있음  


![](/image.png/07.25.PNG)   


  
다시 말해서 노드 중요도는 
모든 질문노드가 데이터를 양갈래로 나누면서 데이터셋들의 지니불순도를 낮추는데 전체적으로 낮춰진 불순도에서 특정속성 하나가 낮춘 불순도가 얼마나 되는지를 계산한 것  

즉, 
특정 속성을 갖는 질문 노드들의 중요도 평균을 구한 것과 비슷   

그렇기 때문에 최종적으로 구한 값을 평균 지니 감소 (Mean Gini Decrease)라고 부르기도 함   


 ![](/image.png/07.26.PNG)  
    

각 속성의 평균 지니 감소를 이용하면 그 속성이 결정트리 안에서 평균적으로 불순도를 얼마나 낮췄는지를 게산할 수 있고 이것으로 그 속성이 얼마나 중요한지를 판단할 수 있음 










