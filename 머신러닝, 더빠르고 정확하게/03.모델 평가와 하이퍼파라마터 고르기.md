## k겹 교차 검증 (k-fold cross validation)  

머신러닝 모델의 성능을 좀 더 정확하게 평가할 수 있는 방법  

전체 데이터를 먼저 k개의 같은 사이즈로 나눔 

예를 들어 k=5, m=1000라고 하면 
1000개의 데이터를 5등분 하는 것  

먼저 
가장 앞에 있는 데이터셋을 test셋으로 사용하고 나머지를 training 셋으로 사용    
성능이 80퍼센트가 나왔다고 하자    


![](/image.png/06.1.PNG)  

그 다음   
두 번째 데이터셋을 test셋으로 사용하고 나머지를 training 셋으로 사용 
성능이 70퍼센트가 나왔다고 하자   


![](/image.png/06.2.PNG)   

나머지 모든 데이터셋에도 반복   

그리고 각각의 성능의 평균을 모델의 전체 성능으로 보는 것     

![](/image.png/06.3.PNG)  


## 그리드 서치 (Grid Search) 

많은 머신러닝 알고리즘은 학습을 하기 전에 미리 정해줘야 하는 변수 또는 파라미터가 있음   
ex) Lasso 모델의 경우 alpha와 max_iter 지정함 (alpha는 손실함수의 정규화 항에 곱해지는 상수, max_iter는 경사 하강법을 몇 번 할 건지)  
이 두 값은 모델이 직접 학습해서 배우는 게 아니라 모델을 만드는 사람이 정해줘야 함    
  
이렇게 머신러닝 모델을 학습시키기 전에 사람이 정해줘야 하는 변수들을 하이퍼 파라미터라고 함  
(sklearn에서는 optional parameter라고 씀)

어떤 값을 넣어주느냐에 따라 성능에 큰 차이가 있을 수 있음  

이번 레슨에서는 좋은 하이퍼 파라미터를 고르는 방법 중 하나인 그리드서치에 대해 알아봄  

우선 각 하이퍼파라미터에 넣어 볼 후보값을 몇 개씩 정함  

모든 후보값의 조합으로 모델을 학습시켰을 때 성능이 가장 좋았던 하이퍼 파라미터 조합을 고름    
이때 이 후보값은 디폴트값(디폴트 값이 얼마인지는 구글링해서 알아보기)과 비슷한 값들로 정함 

예시  


![](/image.png/06.4.PNG)   


각 성능은 k 겹 교차 검증을  이용해서 계산하고 성능이 가장 좋게 나오는 칸에 해당하는 하이퍼 파라미터 값들을 선택! 


